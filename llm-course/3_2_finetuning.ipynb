{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7c4ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, AutoModelForSequenceClassification, Trainer\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e281e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d4fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1725/1725 [00:00<00:00, 14977.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dee7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"data/test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be75485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f532384",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5906243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 02:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.304500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3482386714406176, metrics={'train_runtime': 144.8607, 'train_samples_per_second': 75.963, 'train_steps_per_second': 9.506, 'total_flos': 405114969714960.0, 'train_loss': 0.3482386714406176, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e6bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3281c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.2516727 ,  0.10317594],\n",
       "       [-0.18584032,  0.10619304],\n",
       "       [-0.22810459,  0.1075675 ],\n",
       "       [-0.26167765,  0.11027547],\n",
       "       [-0.23497371,  0.1006903 ],\n",
       "       [-0.21461093,  0.11208803],\n",
       "       [-0.2290157 ,  0.10348621],\n",
       "       [-0.2529328 ,  0.10241468],\n",
       "       [-0.26201728,  0.11166179],\n",
       "       [-0.26061237,  0.11074331],\n",
       "       [-0.2546941 ,  0.1014134 ],\n",
       "       [-0.24636911,  0.10224015],\n",
       "       [-0.17896233,  0.10346542],\n",
       "       [-0.22807224,  0.10610785],\n",
       "       [-0.26691025,  0.09808093],\n",
       "       [-0.24397987,  0.10018104],\n",
       "       [-0.25005573,  0.12315851],\n",
       "       [-0.21560849,  0.09984921],\n",
       "       [-0.27947748,  0.1080706 ],\n",
       "       [-0.18296655,  0.09704208],\n",
       "       [-0.19563515,  0.10610384],\n",
       "       [-0.2201953 ,  0.10578053],\n",
       "       [-0.21511063,  0.10966827],\n",
       "       [-0.2643656 ,  0.10160742],\n",
       "       [-0.21189499,  0.10677373],\n",
       "       [-0.11975335,  0.13165194],\n",
       "       [-0.25923944,  0.10346546],\n",
       "       [-0.2676385 ,  0.11217015],\n",
       "       [-0.24099359,  0.1046038 ],\n",
       "       [-0.2628324 ,  0.091828  ],\n",
       "       [-0.20036316,  0.100327  ],\n",
       "       [-0.28197494,  0.10818857],\n",
       "       [-0.23347676,  0.10378281],\n",
       "       [-0.23672633,  0.10889839],\n",
       "       [-0.2778567 ,  0.10863047],\n",
       "       [-0.25236106,  0.11090198],\n",
       "       [-0.26078248,  0.10839015],\n",
       "       [-0.28810266,  0.10506071],\n",
       "       [-0.27045214,  0.11144386],\n",
       "       [-0.27106687,  0.11163541],\n",
       "       [-0.17966019,  0.11112361],\n",
       "       [-0.18083224,  0.12084961],\n",
       "       [-0.19380988,  0.10914224],\n",
       "       [-0.19612552,  0.11539339],\n",
       "       [-0.24051845,  0.10362562],\n",
       "       [-0.27955154,  0.10330008],\n",
       "       [-0.29132855,  0.10480828],\n",
       "       [-0.1697416 ,  0.12617016],\n",
       "       [-0.25309333,  0.09946842],\n",
       "       [-0.19744769,  0.11166283],\n",
       "       [-0.12799267,  0.12551685],\n",
       "       [-0.23496696,  0.11153368],\n",
       "       [-0.28496036,  0.10606156],\n",
       "       [-0.25702798,  0.10247453],\n",
       "       [-0.2730506 ,  0.09903426],\n",
       "       [-0.18874013,  0.11394814],\n",
       "       [-0.2118788 ,  0.14410259],\n",
       "       [-0.21186475,  0.11280079],\n",
       "       [-0.24485134,  0.10703503],\n",
       "       [-0.23929106,  0.11284667],\n",
       "       [-0.2534341 ,  0.09920873],\n",
       "       [-0.24676917,  0.09965329],\n",
       "       [-0.23680022,  0.10913021],\n",
       "       [-0.26578724,  0.11446079],\n",
       "       [-0.23991084,  0.10439157],\n",
       "       [-0.2622915 ,  0.10193961],\n",
       "       [-0.2661438 ,  0.11111193],\n",
       "       [-0.26892078,  0.10288918],\n",
       "       [-0.23727165,  0.10661863],\n",
       "       [-0.24427466,  0.110176  ],\n",
       "       [-0.23102206,  0.11589839],\n",
       "       [-0.24759187,  0.10996317],\n",
       "       [-0.25472438,  0.1047093 ],\n",
       "       [-0.22688128,  0.1050862 ],\n",
       "       [-0.21086977,  0.11697773],\n",
       "       [-0.16736533,  0.11654929],\n",
       "       [-0.17670533,  0.1284734 ],\n",
       "       [-0.28594318,  0.10213379],\n",
       "       [-0.2253279 ,  0.11560845],\n",
       "       [-0.21023819,  0.11144328],\n",
       "       [-0.2185884 ,  0.10079551],\n",
       "       [-0.25298202,  0.10652198],\n",
       "       [-0.2574806 ,  0.10542116],\n",
       "       [-0.23495902,  0.11963067],\n",
       "       [-0.24164799,  0.10419422],\n",
       "       [-0.25427717,  0.09937595],\n",
       "       [-0.23936878,  0.10079037],\n",
       "       [-0.23297282,  0.11673784],\n",
       "       [-0.18882674,  0.10846973],\n",
       "       [-0.27307785,  0.11683632],\n",
       "       [-0.25885555,  0.10436567],\n",
       "       [-0.23658185,  0.10461124],\n",
       "       [-0.22927825,  0.10429918],\n",
       "       [-0.24146065,  0.09726898],\n",
       "       [-0.26069784,  0.10447588],\n",
       "       [-0.26338464,  0.09951297],\n",
       "       [-0.21367893,  0.10130643],\n",
       "       [-0.22215155,  0.10778334],\n",
       "       [-0.24217485,  0.11113451],\n",
       "       [-0.26086038,  0.0979901 ],\n",
       "       [-0.24122727,  0.10083418],\n",
       "       [-0.21950068,  0.10504912],\n",
       "       [-0.27238542,  0.1106952 ],\n",
       "       [-0.23674689,  0.11398397],\n",
       "       [-0.23494467,  0.10147882],\n",
       "       [-0.2199448 ,  0.11475226],\n",
       "       [-0.2566703 ,  0.10626561],\n",
       "       [-0.10767235,  0.13261524],\n",
       "       [-0.20249088,  0.11310711],\n",
       "       [-0.22726916,  0.10545775],\n",
       "       [-0.18062566,  0.12210148],\n",
       "       [-0.2741506 ,  0.10160884],\n",
       "       [-0.23058723,  0.10172757],\n",
       "       [-0.26592863,  0.1064155 ],\n",
       "       [-0.2545638 ,  0.10119776],\n",
       "       [-0.22299895,  0.10581788],\n",
       "       [-0.24027635,  0.10604161],\n",
       "       [-0.2646109 ,  0.10180771],\n",
       "       [-0.2519464 ,  0.11113249],\n",
       "       [-0.23173541,  0.09435549],\n",
       "       [-0.2788547 ,  0.10607019],\n",
       "       [-0.20414045,  0.09494071],\n",
       "       [-0.22901331,  0.10191856],\n",
       "       [-0.26770425,  0.10614248],\n",
       "       [-0.2531506 ,  0.10636985],\n",
       "       [-0.25465077,  0.09813871],\n",
       "       [-0.25726712,  0.10609888],\n",
       "       [-0.19919628,  0.11039563],\n",
       "       [-0.24132285,  0.11571291],\n",
       "       [-0.17874886,  0.11953228],\n",
       "       [-0.25998974,  0.11988392],\n",
       "       [-0.26067674,  0.10827284],\n",
       "       [-0.17208779,  0.10738855],\n",
       "       [-0.19506809,  0.10010522],\n",
       "       [-0.21535438,  0.11504526],\n",
       "       [-0.2581614 ,  0.09626284],\n",
       "       [-0.23470245,  0.1086235 ],\n",
       "       [-0.280483  ,  0.09853918],\n",
       "       [-0.29733133,  0.12040353],\n",
       "       [-0.25369084,  0.10334589],\n",
       "       [-0.25928998,  0.11146777],\n",
       "       [-0.3141864 ,  0.09473842],\n",
       "       [-0.11152656,  0.10375067],\n",
       "       [-0.2405735 ,  0.10521402],\n",
       "       [-0.25144714,  0.09722201],\n",
       "       [-0.22102322,  0.10636284],\n",
       "       [-0.2801148 ,  0.1060764 ],\n",
       "       [-0.17688136,  0.1087269 ],\n",
       "       [-0.23394126,  0.09640896],\n",
       "       [-0.2444954 ,  0.11040163],\n",
       "       [-0.2389064 ,  0.1022894 ],\n",
       "       [-0.28845125,  0.11637831],\n",
       "       [-0.19889814,  0.10044406],\n",
       "       [-0.2748988 ,  0.10523874],\n",
       "       [-0.26981145,  0.09874714],\n",
       "       [-0.22301249,  0.10899955],\n",
       "       [-0.22897738,  0.11539083],\n",
       "       [-0.07729544,  0.1455172 ],\n",
       "       [-0.22525772,  0.10203218],\n",
       "       [-0.21944337,  0.09700154],\n",
       "       [-0.17404835,  0.12102301],\n",
       "       [-0.2426683 ,  0.10422266],\n",
       "       [-0.29503703,  0.10890742],\n",
       "       [-0.27372447,  0.10517891],\n",
       "       [-0.28189456,  0.10524576],\n",
       "       [-0.23499508,  0.11107028],\n",
       "       [-0.19460982,  0.1027191 ],\n",
       "       [-0.20277804,  0.09953486],\n",
       "       [-0.2482738 ,  0.10875275],\n",
       "       [-0.24599226,  0.10873891],\n",
       "       [-0.23918203,  0.11282413],\n",
       "       [-0.2381909 ,  0.11310101],\n",
       "       [-0.2752038 ,  0.09968632],\n",
       "       [-0.27265465,  0.10418348],\n",
       "       [-0.24793653,  0.11128768],\n",
       "       [-0.20347108,  0.1115695 ],\n",
       "       [-0.24846354,  0.10889654],\n",
       "       [-0.20011567,  0.10911807],\n",
       "       [-0.2780005 ,  0.11419847],\n",
       "       [-0.2457705 ,  0.09047449],\n",
       "       [-0.19046229,  0.12776491],\n",
       "       [-0.25023067,  0.11380464],\n",
       "       [-0.25557858,  0.1072785 ],\n",
       "       [-0.24739444,  0.10102795],\n",
       "       [-0.19018924,  0.10469852],\n",
       "       [-0.27032387,  0.10195161],\n",
       "       [-0.2168755 ,  0.09552982],\n",
       "       [-0.24247079,  0.10021226],\n",
       "       [-0.23295897,  0.10234617],\n",
       "       [-0.2467558 ,  0.09877171],\n",
       "       [-0.25416043,  0.11269376],\n",
       "       [-0.23697779,  0.10121646],\n",
       "       [-0.27126127,  0.10963708],\n",
       "       [-0.24967875,  0.1051652 ],\n",
       "       [-0.20019951,  0.11009024],\n",
       "       [-0.22944744,  0.10319543],\n",
       "       [-0.2804634 ,  0.10517636],\n",
       "       [-0.17362207,  0.10048318],\n",
       "       [-0.2666971 ,  0.10589443],\n",
       "       [-0.19879977,  0.11019933],\n",
       "       [-0.23928678,  0.09800561],\n",
       "       [-0.2363467 ,  0.10207525],\n",
       "       [-0.2714337 ,  0.10163078],\n",
       "       [-0.2513076 ,  0.11185776],\n",
       "       [-0.22001556,  0.10230873],\n",
       "       [-0.20909108,  0.1120552 ],\n",
       "       [-0.14473146,  0.14757758],\n",
       "       [-0.12544751,  0.13513397],\n",
       "       [-0.2367468 ,  0.10751935],\n",
       "       [-0.23795947,  0.11211932],\n",
       "       [-0.25214928,  0.11825935],\n",
       "       [-0.2514784 ,  0.11101326],\n",
       "       [-0.2714685 ,  0.10028355],\n",
       "       [-0.25890118,  0.10627304],\n",
       "       [-0.290892  ,  0.11511672],\n",
       "       [-0.2609644 ,  0.10544059],\n",
       "       [-0.25689685,  0.10331062],\n",
       "       [-0.25367224,  0.11332919],\n",
       "       [-0.23553008,  0.11615535],\n",
       "       [-0.20440964,  0.12361275],\n",
       "       [-0.27806574,  0.1132293 ],\n",
       "       [-0.25957775,  0.11007352],\n",
       "       [-0.24048102,  0.11193085],\n",
       "       [-0.13527471,  0.12606381],\n",
       "       [-0.24691018,  0.10610449],\n",
       "       [-0.27807254,  0.11737374],\n",
       "       [-0.25997603,  0.09751811],\n",
       "       [-0.21796489,  0.10269371],\n",
       "       [-0.251184  ,  0.10639152],\n",
       "       [-0.22096902,  0.11692268],\n",
       "       [-0.28262067,  0.10554908],\n",
       "       [-0.20783658,  0.10569015],\n",
       "       [-0.20488875,  0.10840476],\n",
       "       [-0.2871638 ,  0.10528328],\n",
       "       [-0.244374  ,  0.10189445],\n",
       "       [-0.21282874,  0.10754005],\n",
       "       [-0.21782412,  0.10937181],\n",
       "       [-0.25883368,  0.10089654],\n",
       "       [-0.25896895,  0.10708553],\n",
       "       [-0.27964747,  0.11237666],\n",
       "       [-0.25520015,  0.09000663],\n",
       "       [-0.22969146,  0.10722405],\n",
       "       [-0.24782974,  0.10028415],\n",
       "       [-0.1926974 ,  0.11054488],\n",
       "       [-0.25540018,  0.1084108 ],\n",
       "       [-0.23266149,  0.10792744],\n",
       "       [-0.1624289 ,  0.10761922],\n",
       "       [-0.21237986,  0.11945213],\n",
       "       [-0.25269777,  0.09999379],\n",
       "       [-0.21566033,  0.11874017],\n",
       "       [-0.20595655,  0.11484295],\n",
       "       [-0.20178911,  0.11366613],\n",
       "       [-0.26402813,  0.09600133],\n",
       "       [-0.19139731,  0.12583229],\n",
       "       [-0.258774  ,  0.10330514],\n",
       "       [-0.19928683,  0.10234843],\n",
       "       [-0.26077837,  0.10254568],\n",
       "       [-0.20937157,  0.10345486],\n",
       "       [-0.22293949,  0.11258435],\n",
       "       [-0.22009149,  0.10457308],\n",
       "       [-0.23942994,  0.10342404],\n",
       "       [-0.22245093,  0.1148146 ],\n",
       "       [-0.2657786 ,  0.10950644],\n",
       "       [-0.21688567,  0.09949668],\n",
       "       [-0.23360099,  0.09592994],\n",
       "       [-0.16350023,  0.13988829],\n",
       "       [-0.19342919,  0.11330127],\n",
       "       [-0.18456133,  0.11179335],\n",
       "       [-0.2713077 ,  0.11045673],\n",
       "       [-0.20946695,  0.10500524],\n",
       "       [-0.20435753,  0.11432391],\n",
       "       [-0.2851599 ,  0.11087226],\n",
       "       [-0.21568829,  0.0993466 ],\n",
       "       [-0.24214983,  0.10681239],\n",
       "       [-0.26099038,  0.10583415],\n",
       "       [-0.26662084,  0.11116365],\n",
       "       [-0.21955936,  0.09687993],\n",
       "       [-0.2396307 ,  0.10094792],\n",
       "       [-0.26823163,  0.10963827],\n",
       "       [-0.21295817,  0.10717896],\n",
       "       [-0.2208175 ,  0.11625487],\n",
       "       [-0.21904239,  0.099594  ],\n",
       "       [-0.25696495,  0.10151609],\n",
       "       [-0.2157018 ,  0.11309709],\n",
       "       [-0.3010417 ,  0.1063658 ],\n",
       "       [-0.22981806,  0.10224863],\n",
       "       [-0.26644003,  0.11346531],\n",
       "       [-0.2213627 ,  0.1056921 ],\n",
       "       [-0.25190997,  0.10044082],\n",
       "       [-0.22351247,  0.1105136 ],\n",
       "       [-0.1588982 ,  0.12675273],\n",
       "       [-0.22823429,  0.11656091],\n",
       "       [-0.25819516,  0.11512761],\n",
       "       [-0.2658749 ,  0.10768276],\n",
       "       [-0.26649013,  0.11131939],\n",
       "       [-0.22122148,  0.11388401],\n",
       "       [-0.23273899,  0.10223871],\n",
       "       [-0.09881628,  0.13450411],\n",
       "       [-0.2619679 ,  0.10049951],\n",
       "       [ 0.00316703,  0.17339757],\n",
       "       [-0.22275138,  0.11318637],\n",
       "       [-0.3037681 ,  0.10802098],\n",
       "       [-0.23730232,  0.11064176],\n",
       "       [-0.26056647,  0.10441381],\n",
       "       [-0.26528746,  0.09804243],\n",
       "       [-0.28143597,  0.10264354],\n",
       "       [-0.2434416 ,  0.1022367 ],\n",
       "       [-0.2597196 ,  0.10094994],\n",
       "       [-0.22219159,  0.09757402],\n",
       "       [-0.26018476,  0.10094137],\n",
       "       [-0.26636654,  0.10822412],\n",
       "       [-0.24388379,  0.09949857],\n",
       "       [-0.16289268,  0.12663266],\n",
       "       [-0.2588034 ,  0.10764271],\n",
       "       [-0.2750688 ,  0.10367646],\n",
       "       [-0.20161489,  0.09837569],\n",
       "       [-0.25345707,  0.10208554],\n",
       "       [-0.23621272,  0.10398179],\n",
       "       [-0.13751064,  0.13072675],\n",
       "       [-0.23075579,  0.11486955],\n",
       "       [-0.19580826,  0.10427617],\n",
       "       [-0.23134395,  0.09827082],\n",
       "       [-0.17920116,  0.10791822],\n",
       "       [-0.15620837,  0.12249415],\n",
       "       [-0.22822809,  0.10611367],\n",
       "       [-0.30584624,  0.10172983],\n",
       "       [-0.2470661 ,  0.10829316],\n",
       "       [-0.2837939 ,  0.11354171],\n",
       "       [-0.2590783 ,  0.10411111],\n",
       "       [-0.25816473,  0.10613749],\n",
       "       [-0.28303277,  0.10733213],\n",
       "       [-0.2296613 ,  0.10913716],\n",
       "       [-0.2628883 ,  0.09519459],\n",
       "       [-0.2624758 ,  0.11131036],\n",
       "       [-0.25569832,  0.10783423],\n",
       "       [-0.27541584,  0.08597504],\n",
       "       [-0.20339318,  0.12167092],\n",
       "       [-0.2698273 ,  0.08955093],\n",
       "       [-0.21759456,  0.11111081],\n",
       "       [-0.25554115,  0.10912597],\n",
       "       [-0.24876343,  0.09650172],\n",
       "       [-0.25887048,  0.10925181],\n",
       "       [-0.19563149,  0.10001741],\n",
       "       [-0.20373958,  0.13044816],\n",
       "       [-0.2586546 ,  0.1052677 ],\n",
       "       [-0.2836881 ,  0.10088479],\n",
       "       [-0.25365475,  0.1039202 ],\n",
       "       [-0.27522403,  0.10396832],\n",
       "       [-0.23333482,  0.10388189],\n",
       "       [-0.25927943,  0.10330512],\n",
       "       [-0.25819713,  0.11301308],\n",
       "       [-0.22418867,  0.10586672],\n",
       "       [-0.23254558,  0.10674506],\n",
       "       [-0.2480637 ,  0.10400757],\n",
       "       [-0.2550215 ,  0.10589785],\n",
       "       [-0.18354146,  0.11246085],\n",
       "       [-0.2003165 ,  0.10260122],\n",
       "       [-0.22907674,  0.10443234],\n",
       "       [-0.2634179 ,  0.10536033],\n",
       "       [-0.23982494,  0.10534268],\n",
       "       [-0.16874483,  0.12569222],\n",
       "       [-0.18397532,  0.12403602],\n",
       "       [-0.2594015 ,  0.10379518],\n",
       "       [-0.2659816 ,  0.10318092],\n",
       "       [-0.3233027 ,  0.11713564],\n",
       "       [-0.2509267 ,  0.09676196],\n",
       "       [-0.24732207,  0.09969348],\n",
       "       [-0.2169559 ,  0.10072754],\n",
       "       [-0.20366071,  0.11569864],\n",
       "       [-0.2224338 ,  0.11316326],\n",
       "       [-0.26017836,  0.10465294],\n",
       "       [-0.24348007,  0.11038917],\n",
       "       [-0.25089252,  0.10294326],\n",
       "       [-0.23711511,  0.09740914],\n",
       "       [-0.22817375,  0.10406445],\n",
       "       [-0.25926134,  0.0971521 ],\n",
       "       [-0.23007843,  0.106866  ],\n",
       "       [-0.24796118,  0.10175768],\n",
       "       [-0.25749898,  0.10413538],\n",
       "       [-0.2732682 ,  0.10099337],\n",
       "       [-0.21489841,  0.11359867],\n",
       "       [-0.27955887,  0.10446069],\n",
       "       [-0.26253736,  0.11218374],\n",
       "       [-0.27020702,  0.10179783],\n",
       "       [-0.26322043,  0.10769892],\n",
       "       [-0.20857719,  0.10672969],\n",
       "       [-0.16626018,  0.12289249],\n",
       "       [-0.17851278,  0.12381829],\n",
       "       [-0.2728284 ,  0.10489143],\n",
       "       [-0.26078445,  0.10730124],\n",
       "       [-0.2655584 ,  0.10597111],\n",
       "       [-0.28024325,  0.1080944 ],\n",
       "       [-0.24876796,  0.09592016],\n",
       "       [-0.27340594,  0.11031193],\n",
       "       [-0.2500567 ,  0.10764614],\n",
       "       [-0.24334495,  0.11539712],\n",
       "       [-0.26954156,  0.10372674],\n",
       "       [-0.21508284,  0.10941701],\n",
       "       [-0.17743286,  0.12725747],\n",
       "       [-0.2776721 ,  0.10325842],\n",
       "       [-0.23129731,  0.10029013],\n",
       "       [-0.2505035 ,  0.10544952],\n",
       "       [-0.21066673,  0.10273045],\n",
       "       [-0.2581666 ,  0.11159452],\n",
       "       [-0.20066606,  0.11877409],\n",
       "       [-0.25405517,  0.10034728],\n",
       "       [-0.20724908,  0.10606238],\n",
       "       [-0.23436089,  0.10518519]], dtype=float32), label_ids=array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.6406205892562866, 'test_model_preparation_time': 0.0016, 'test_runtime': 2.0584, 'test_samples_per_second': 198.209, 'test_steps_per_second': 24.776})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56dfee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor(predictions.predictions).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b1786d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45194e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d48713a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68f34ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = torch.tensor(logits).argmax(dim=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "884c692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"data/test-trainer-2\", eval_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0c326ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f34db862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 02:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.362850</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.882143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.512800</td>\n",
       "      <td>0.470066</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.889279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>0.656615</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.900685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/donaldkapyouo/Documents/bitmarck/ai-cookbook/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3240856400588845, metrics={'train_runtime': 145.4943, 'train_samples_per_second': 75.632, 'train_steps_per_second': 9.464, 'total_flos': 405114969714960.0, 'train_loss': 0.3240856400588845, 'epoch': 3.0})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
